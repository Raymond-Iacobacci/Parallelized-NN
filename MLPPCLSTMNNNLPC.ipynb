{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLPPCLSTMNNNLPC.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Raymond-Iacobacci/Parallelized-NN/blob/main/MLPPCLSTMNNNLPC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7UJ09nRuSkG"
      },
      "source": [
        "# Load and format datasets "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vJRftxWt342",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfbae9cb-ead5-4ee4-c928-ec8f56e9cdfe"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "#from python.keras import backend as k\n",
        "from keras.datasets import imdb\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Conv1D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence\n",
        "# fix random seed for reproducibility\n",
        "np.random.seed(7)\n",
        "!pip install tf-nightly"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tf-nightly in /usr/local/lib/python3.7/dist-packages (2.5.0.dev20210324)\n",
            "Requirement already satisfied: tb-nightly~=2.5.0.a in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (2.5.0a20210324)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (3.7.4.3)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (3.3.0)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (0.4.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.6.3)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.1.0)\n",
            "Requirement already satisfied: grpcio~=1.34.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.34.1)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.12)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (0.36.2)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.1.2)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.19.5)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (3.12.4)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.12.1)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (0.2.0)\n",
            "Requirement already satisfied: tf-estimator-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (2.5.0.dev2021032401)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (0.10.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.5.0.a->tf-nightly) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.5.0.a->tf-nightly) (3.3.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.5.0.a->tf-nightly) (54.1.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.5.0.a->tf-nightly) (2.23.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.5.0.a->tf-nightly) (1.27.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.5.0.a->tf-nightly) (0.4.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.5.0.a->tf-nightly) (0.6.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.5.0.a->tf-nightly) (1.8.0)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tf-nightly) (1.5.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tb-nightly~=2.5.0.a->tf-nightly) (3.7.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.5.0.a->tf-nightly) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.5.0.a->tf-nightly) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.5.0.a->tf-nightly) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.5.0.a->tf-nightly) (2.10)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tb-nightly~=2.5.0.a->tf-nightly) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tb-nightly~=2.5.0.a->tf-nightly) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tb-nightly~=2.5.0.a->tf-nightly) (4.2.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tb-nightly~=2.5.0.a->tf-nightly) (1.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tb-nightly~=2.5.0.a->tf-nightly) (3.4.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tb-nightly~=2.5.0.a->tf-nightly) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tb-nightly~=2.5.0.a->tf-nightly) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeWQxvg4vDut",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "767d2f9b-0682-4311-fbb6-95f2294b675e"
      },
      "source": [
        "# load the dataset but only keep the top n words, zero the rest\n",
        "top_words = 5000\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:155: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7ZSGsejwpYR"
      },
      "source": [
        "# truncate and pad input sequences\n",
        "max_review_length = 500\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKQ-MckVw8le"
      },
      "source": [
        "# Making model 1 (LSTM)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4o7YP42w-ky",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c091023b-33db-4568-c95e-543543aeb8a1"
      },
      "source": [
        "embedding_vecor_length = 32\n",
        "model_5 = Sequential()\n",
        "model_5.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
        "model_5.add(LSTM(50))\n",
        "model_5.add(Dense(1, activation = 'sigmoid'))\n",
        "model_5.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "print(model_5.summary())\n",
        "model_5.fit(X_train, y_train, epochs=3, batch_size=64)\n",
        "# Final evaluation of the model\n",
        "scores = model_5.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 500, 32)           160000    \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 50)                16600     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 51        \n",
            "=================================================================\n",
            "Total params: 176,651\n",
            "Trainable params: 176,651\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/3\n",
            "391/391 [==============================] - 97s 245ms/step - loss: 0.5515 - accuracy: 0.6904\n",
            "Epoch 2/3\n",
            "391/391 [==============================] - 95s 243ms/step - loss: 0.2715 - accuracy: 0.8940\n",
            "Epoch 3/3\n",
            "391/391 [==============================] - 96s 245ms/step - loss: 0.2092 - accuracy: 0.9206\n",
            "Accuracy: 87.72%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "as90M6_C8m9J"
      },
      "source": [
        "from keras import backend as K\n",
        "model_LSTM = K.function([model_5.layers[0].input],\n",
        "                                  [model_5.layers[2].output])\n",
        "layer_output = model_LSTM([X_test])[0]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMlI29pc91zI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7f13494e-5343-4b55-fe19-ca40ed44a2da"
      },
      "source": [
        "print(model_LSTM([X_test])[0][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.07295863]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wz8YxUxlDmzY"
      },
      "source": [
        "# Making model 2 (C1D)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOp214MvG6j3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3148705-8504-4761-9f3c-13d6598d0c6d"
      },
      "source": [
        "embedding_vecor_length = 32\n",
        "model_3 = Sequential()\n",
        "model_3.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
        "model_3.add(Conv1D(1,4))\n",
        "model_3.add(Flatten())\n",
        "model_3.add(Dense(1, activation = 'sigmoid'))\n",
        "model_3.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "print(model_3.summary())\n",
        "model_3.fit(X_train, y_train, epochs=3, batch_size=64)\n",
        "# Final evaluation of the model\n",
        "scores = model_3.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 500, 32)           160000    \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 497, 1)            129       \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 497)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 498       \n",
            "=================================================================\n",
            "Total params: 160,627\n",
            "Trainable params: 160,627\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/3\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 0.6097 - accuracy: 0.6282\n",
            "Epoch 2/3\n",
            "391/391 [==============================] - 16s 42ms/step - loss: 0.2452 - accuracy: 0.9022\n",
            "Epoch 3/3\n",
            "391/391 [==============================] - 16s 42ms/step - loss: 0.1920 - accuracy: 0.9248\n",
            "Accuracy: 87.81%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhBvWIiUSxiv"
      },
      "source": [
        "from keras import backend as K\n",
        "model_Conv1D = K.function([model_3.layers[0].input],\n",
        "                         [model_3.layers[3].output])\n",
        "layer_output = model_Conv1D([X_test])[0]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Od6QxV1dTdHl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ddd5e0d8-657e-4dfb-bead-5decdbd8c803"
      },
      "source": [
        "print(model_Conv1D([X_test])[0][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.28339362]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vc0yFB77Vno9"
      },
      "source": [
        "# Making model 3 (MTP)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opjMHd94Vv3j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "584f74ce-568c-4d58-cae8-c8b49f05d6f1"
      },
      "source": [
        "embedding_vecor_length = 32\n",
        "model_4 = Sequential()\n",
        "model_4.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
        "model_4.add(Dense(100, activation = 'relu'))\n",
        "model_4.add(Dense(10, activation = 'relu'))\n",
        "model_4.add(Flatten())\n",
        "model_4.add(Dense(1, activation = 'sigmoid'))\n",
        "model_4.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "print(model_4.summary())\n",
        "model_4.fit(X_train, y_train, epochs=3, batch_size=64)\n",
        "# Final evaluation of the model\n",
        "scores = model_4.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 500, 32)           160000    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 500, 100)          3300      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 500, 10)           1010      \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 5000)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 5001      \n",
            "=================================================================\n",
            "Total params: 169,311\n",
            "Trainable params: 169,311\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/3\n",
            "391/391 [==============================] - 22s 54ms/step - loss: 0.6016 - accuracy: 0.6132\n",
            "Epoch 2/3\n",
            "391/391 [==============================] - 21s 54ms/step - loss: 0.2292 - accuracy: 0.9114\n",
            "Epoch 3/3\n",
            "391/391 [==============================] - 21s 55ms/step - loss: 0.1840 - accuracy: 0.9301\n",
            "Accuracy: 87.58%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6cG7zLlWwye"
      },
      "source": [
        "from keras import backend as K\n",
        "model_MTP = K.function([model_4.layers[0].input],\n",
        "                         [model_4.layers[4].output])\n",
        "layer_output = model_MTP([X_test])[0]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3u04m9LXR1p"
      },
      "source": [
        "# Making composite model (MTP)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqNjsfyui00j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a102608-a9ba-4468-a071-f889420c1453"
      },
      "source": [
        "print(X_train.shape)\n",
        "final_train = np.zeros(shape = (25000, 3))\n",
        "LSTM_list = model_LSTM([X_train])[0]\n",
        "Conv1D_list = model_Conv1D([X_train])[0]\n",
        "MTP_list = model_MTP([X_train])[0]\n",
        "print(\"Lists copied\")\n",
        "for i in range(25000):\n",
        "  final_train[i][0] = LSTM_list[i]\n",
        "  final_train[i][1] = Conv1D_list[i]\n",
        "  final_train[i][2] = MTP_list[i]\n",
        "  if i%500 == 0:\n",
        "    print(i,\"/\",25000)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(25000, 500)\n",
            "Lists copied\n",
            "0 / 25000\n",
            "500 / 25000\n",
            "1000 / 25000\n",
            "1500 / 25000\n",
            "2000 / 25000\n",
            "2500 / 25000\n",
            "3000 / 25000\n",
            "3500 / 25000\n",
            "4000 / 25000\n",
            "4500 / 25000\n",
            "5000 / 25000\n",
            "5500 / 25000\n",
            "6000 / 25000\n",
            "6500 / 25000\n",
            "7000 / 25000\n",
            "7500 / 25000\n",
            "8000 / 25000\n",
            "8500 / 25000\n",
            "9000 / 25000\n",
            "9500 / 25000\n",
            "10000 / 25000\n",
            "10500 / 25000\n",
            "11000 / 25000\n",
            "11500 / 25000\n",
            "12000 / 25000\n",
            "12500 / 25000\n",
            "13000 / 25000\n",
            "13500 / 25000\n",
            "14000 / 25000\n",
            "14500 / 25000\n",
            "15000 / 25000\n",
            "15500 / 25000\n",
            "16000 / 25000\n",
            "16500 / 25000\n",
            "17000 / 25000\n",
            "17500 / 25000\n",
            "18000 / 25000\n",
            "18500 / 25000\n",
            "19000 / 25000\n",
            "19500 / 25000\n",
            "20000 / 25000\n",
            "20500 / 25000\n",
            "21000 / 25000\n",
            "21500 / 25000\n",
            "22000 / 25000\n",
            "22500 / 25000\n",
            "23000 / 25000\n",
            "23500 / 25000\n",
            "24000 / 25000\n",
            "24500 / 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTJ4I3BZdGmF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13acef06-2306-48d6-ff13-2b5360d3775c"
      },
      "source": [
        "model_fin = Sequential()\n",
        "model_fin.add(Dense(7, activation = 'relu', input_shape = (3,)))\n",
        "model_fin.add(Dense(20, activation = 'relu'))\n",
        "model_fin.add(Dense(1, activation = 'sigmoid'))\n",
        "model_fin.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "model_fin.fit(final_train, y_train, epochs=7, batch_size=64)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/7\n",
            "391/391 [==============================] - 1s 1ms/step - loss: 0.4955 - accuracy: 0.7700\n",
            "Epoch 2/7\n",
            "391/391 [==============================] - 0s 1ms/step - loss: 0.1461 - accuracy: 0.9486\n",
            "Epoch 3/7\n",
            "391/391 [==============================] - 0s 1ms/step - loss: 0.1393 - accuracy: 0.9497\n",
            "Epoch 4/7\n",
            "391/391 [==============================] - 0s 1ms/step - loss: 0.1422 - accuracy: 0.9490\n",
            "Epoch 5/7\n",
            "391/391 [==============================] - 0s 1ms/step - loss: 0.1367 - accuracy: 0.9514\n",
            "Epoch 6/7\n",
            "391/391 [==============================] - 0s 1ms/step - loss: 0.1328 - accuracy: 0.9518\n",
            "Epoch 7/7\n",
            "391/391 [==============================] - 0s 1ms/step - loss: 0.1414 - accuracy: 0.9492\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f965e9da7d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    }
  ]
}